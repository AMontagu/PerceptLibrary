#############################################################################
## Copyright (c) 1996, Carnegie Mellon University, Cambridge University,
## Ronald Rosenfeld and Philip Clarkson
## Version 3, Copyright (c) 2006, Carnegie Mellon University 
## Contributors includes Wen Xu, Ananlada Chotimongkol, 
## David Huggins-Daines, Arthur Chan and Alan Black 
#############################################################################
=============================================================================
===============  This file was produced by the CMU-Cambridge  ===============
===============     Statistical Language Modeling Toolkit     ===============
=============================================================================
This is a 3-gram language model, based on a vocabulary of 15 words,
  which begins "</s>", "<s>", "avant"...
This is a CLOSED-vocabulary model
  (OOVs eliminated from training data and are forbidden in test data)
Good-Turing discounting was applied.
1-gram frequency of frequency : 11 
2-gram frequency of frequency : 19 0 1 0 0 0 0 
3-gram frequency of frequency : 27 0 1 0 0 0 0 
1-gram discounting ratios : 0.92 
2-gram discounting ratios : 
3-gram discounting ratios : 
This file is in the ARPA-standard format introduced by Doug Paul.

p(wd3|wd1,wd2)= if(trigram exists)           p_3(wd1,wd2,wd3)
                else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2)
                else                         p(wd3|w2)

p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2)
            else              bo_wt_1(wd1)*p_1(wd2)

All probs and back-off weights (bo_wt) are given in log10 form.

Data formats:

Beginning of data mark: \data\
ngram 1=nr            # number of 1-grams
ngram 2=nr            # number of 2-grams
ngram 3=nr            # number of 3-grams

\1-grams:
p_1     wd_1 bo_wt_1
\2-grams:
p_2     wd_1 wd_2 bo_wt_2
\3-grams:
p_3     wd_1 wd_2 wd_3 

end of data mark: \end\

\data\
ngram 1=15
ngram 2=21
ngram 3=28

\1-grams:
-0.5740 </s>	-0.8653
-0.5740 <s>	-1.0495
-1.5149 avant	-0.3424
-1.5149 derriere	-0.3424
-1.0000 detection	-0.8033
-1.5149 droite	-0.3424
-1.5149 faciale	-0.3424
-1.5149 faciale</s>	-0.3424
-1.5149 gauche	-0.3424
-1.5149 reconnaissance	-0.4636
-1.5149 sourires	-0.3424
-1.5149 stop	0.0000
-1.5149 video	-0.3424
-1.5149 yeux	-0.3424
-1.5149 ﻿<s>	-0.4636

\2-grams:
-0.0458 </s> <s> 0.2218
-0.8751 <s> derriere 0.1761
-0.5740 <s> detection 0.2430
-0.8751 <s> droite 0.1761
-0.8751 <s> gauche 0.1761
-0.8751 <s> reconnaissance 0.1761
-0.8751 <s> video 0.1761
-0.1761 avant </s> 0.6990
-0.1761 derriere </s> 0.6990
-0.5441 detection faciale 0.1761
-0.5441 detection sourires 0.1761
-0.5441 detection yeux 0.1761
-0.1761 droite </s> 0.6990
-0.1761 faciale </s> 0.6990
-0.1761 faciale</s> <s> -0.2998
-0.1761 gauche </s> 0.6990
-0.1761 reconnaissance faciale</s> 0.1761
-0.1761 sourires </s> 0.6990
-0.1761 video </s> 0.6990
-0.1761 yeux </s> 0.6990
-0.1761 ﻿<s> avant 0.1761

\3-grams:
-0.9542 </s> <s> derriere 
-0.4771 </s> <s> detection 
-0.9542 </s> <s> droite 
-0.9542 </s> <s> gauche 
-0.9542 </s> <s> reconnaissance 
-0.9542 </s> <s> video 
-0.3010 <s> derriere </s> 
-0.6021 <s> detection faciale 
-0.6021 <s> detection sourires 
-0.6021 <s> detection yeux 
-0.3010 <s> droite </s> 
-0.3010 <s> gauche </s> 
-0.3010 <s> reconnaissance faciale</s> 
-0.3010 <s> video </s> 
-0.3010 avant </s> <s> 
-0.3010 derriere </s> <s> 
-0.3010 detection faciale </s> 
-0.3010 detection sourires </s> 
-0.3010 detection yeux </s> 
-0.3010 droite </s> <s> 
-0.3010 faciale </s> <s> 
-0.3010 faciale</s> <s> stop 
-0.3010 gauche </s> <s> 
-0.3010 reconnaissance faciale</s> <s> 
-0.3010 sourires </s> <s> 
-0.3010 video </s> <s> 
-0.3010 yeux </s> <s> 
-0.3010 ﻿<s> avant </s> 

\end\
