#############################################################################
## Copyright (c) 1996, Carnegie Mellon University, Cambridge University,
## Ronald Rosenfeld and Philip Clarkson
## Version 3, Copyright (c) 2006, Carnegie Mellon University 
## Contributors includes Wen Xu, Ananlada Chotimongkol, 
## David Huggins-Daines, Arthur Chan and Alan Black 
#############################################################################
=============================================================================
===============  This file was produced by the CMU-Cambridge  ===============
===============     Statistical Language Modeling Toolkit     ===============
=============================================================================
This is a 3-gram language model, based on a vocabulary of 16 words,
  which begins "</s>", "<s>", "avant"...
This is a CLOSED-vocabulary model
  (OOVs eliminated from training data and are forbidden in test data)
Good-Turing discounting was applied.
1-gram frequency of frequency : 12 
2-gram frequency of frequency : 21 0 1 0 0 0 0 
3-gram frequency of frequency : 30 0 1 0 0 0 0 
1-gram discounting ratios : 0.92 
2-gram discounting ratios : 
3-gram discounting ratios : 
This file is in the ARPA-standard format introduced by Doug Paul.

p(wd3|wd1,wd2)= if(trigram exists)           p_3(wd1,wd2,wd3)
                else if(bigram w1,w2 exists) bo_wt_2(w1,w2)*p(wd3|wd2)
                else                         p(wd3|w2)

p(wd2|wd1)= if(bigram exists) p_2(wd1,wd2)
            else              bo_wt_1(wd1)*p_1(wd2)

All probs and back-off weights (bo_wt) are given in log10 form.

Data formats:

Beginning of data mark: \data\
ngram 1=nr            # number of 1-grams
ngram 2=nr            # number of 2-grams
ngram 3=nr            # number of 3-grams

\1-grams:
p_1     wd_1 bo_wt_1
\2-grams:
p_2     wd_1 wd_2 bo_wt_2
\3-grams:
p_3     wd_1 wd_2 wd_3 

end of data mark: \end\

\data\
ngram 1=16
ngram 2=23
ngram 3=31

\1-grams:
-0.5643 </s>	-0.9031
-0.5643 <s>	-1.1004
-1.5533 avant	-0.3388
-1.5533 derriere	-0.3388
-1.0414 detection	-0.8070
-1.5533 droite	-0.3388
-1.5533 faciale	-0.3388
-1.5533 faciale</s>	-0.3388
-1.5533 gauche	-0.3388
-1.5533 reconnaissance	-0.4648
-1.5533 robotlab	0.0000
-1.5533 sourires	-0.3388
-1.5533 stop	-0.3388
-1.5533 video	-0.3388
-1.5533 yeux	-0.3388
-1.5533 ﻿<s>	-0.4648

\2-grams:
-0.0414 </s> <s> -0.2412
-0.9294 <s> derriere 0.1761
-0.6284 <s> detection 0.2430
-0.9294 <s> droite 0.1761
-0.9294 <s> gauche 0.1761
-0.9294 <s> reconnaissance 0.1761
-0.9294 <s> stop 0.1761
-0.9294 <s> video 0.1761
-0.1761 avant </s> 0.7404
-0.1761 derriere </s> 0.7404
-0.5441 detection faciale 0.1761
-0.5441 detection sourires 0.1761
-0.5441 detection yeux 0.1761
-0.1761 droite </s> 0.7404
-0.1761 faciale </s> 0.7404
-0.1761 faciale</s> <s> -0.2467
-0.1761 gauche </s> 0.7404
-0.1761 reconnaissance faciale</s> 0.1761
-0.1761 sourires </s> 0.7404
-0.1761 stop </s> 0.7404
-0.1761 video </s> 0.7404
-0.1761 yeux </s> 0.7404
-0.1761 ﻿<s> avant 0.1761

\3-grams:
-1.0000 </s> <s> derriere 
-0.5229 </s> <s> detection 
-1.0000 </s> <s> droite 
-1.0000 </s> <s> gauche 
-1.0000 </s> <s> reconnaissance 
-1.0000 </s> <s> robotlab 
-1.0000 </s> <s> video 
-0.3010 <s> derriere </s> 
-0.6021 <s> detection faciale 
-0.6021 <s> detection sourires 
-0.6021 <s> detection yeux 
-0.3010 <s> droite </s> 
-0.3010 <s> gauche </s> 
-0.3010 <s> reconnaissance faciale</s> 
-0.3010 <s> stop </s> 
-0.3010 <s> video </s> 
-0.3010 avant </s> <s> 
-0.3010 derriere </s> <s> 
-0.3010 detection faciale </s> 
-0.3010 detection sourires </s> 
-0.3010 detection yeux </s> 
-0.3010 droite </s> <s> 
-0.3010 faciale </s> <s> 
-0.3010 faciale</s> <s> stop 
-0.3010 gauche </s> <s> 
-0.3010 reconnaissance faciale</s> <s> 
-0.3010 sourires </s> <s> 
-0.3010 stop </s> <s> 
-0.3010 video </s> <s> 
-0.3010 yeux </s> <s> 
-0.3010 ﻿<s> avant </s> 

\end\
